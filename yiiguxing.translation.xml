<application>
  <component name="AppStorage">
    <histories>
      <item value="focus Cleanup" />
      <item value="overflow" />
      <item value="Set whether any jobs defined on this SchedulerFactoryBean should overwrite existing job definitions. Default is &quot;false&quot;, to not overwrite already registered jobs that have been read in from a persistent job store." />
      <item value="type Aliases Package" />
      <item value="inventory Auto" />
      <item value="inventory" />
      <item value="chip" />
      <item value="bill" />
      <item value="apply" />
      <item value="inform" />
      <item value="finance" />
      <item value="applet" />
      <item value="advertise" />
      <item value="access" />
      <item value="Circle" />
      <item value="size Circle" />
      <item value="concrete" />
      <item value="Create a predicate for testing the arguments for equality. @param x expression @param y object @return equality predicate" />
      <item value="create Query" />
      <item value="get Criteria Builder" />
      <item value="flag" />
      <item value="assignable From" />
      <item value="detach" />
      <item value="get Related Form Future" />
      <item value="effective Person" />
      <item value="Hash table based implementation of the &lt;tt&gt;Map&lt;tt&gt; interface. This implementation provides all of the optional map operations, and permits &lt;tt&gt;null&lt;tt&gt; values and the &lt;tt&gt;null&lt;tt&gt; key. (The &lt;tt&gt;HashMap&lt;tt&gt; class is roughly equivalent to &lt;tt&gt;Hashtable&lt;tt&gt;, except that it is unsynchronized and permits nulls.) This class makes no guarantees as to the order of the map; in particular, it does not guarantee that the order will remain constant over time. &lt;p&gt;This implementation provides constant-time performance for the basic operations (&lt;tt&gt;get&lt;tt&gt; and &lt;tt&gt;put&lt;tt&gt;), assuming the hash function disperses the elements properly among the buckets. Iteration over collection views requires time proportional to the &quot;capacity&quot; of the &lt;tt&gt;HashMap&lt;tt&gt; instance (the number of buckets) plus its size (the number of key-value mappings). Thus, it's very important not to set the initial capacity too high (or the load factor too low) if iteration performance is important. &lt;p&gt;An instance of &lt;tt&gt;HashMap&lt;tt&gt; has two parameters that affect its performance: &lt;i&gt;initial capacity&lt;i&gt; and &lt;i&gt;load factor&lt;i&gt;. The &lt;i&gt;capacity&lt;i&gt; is the number of buckets in the hash table, and the initial capacity is simply the capacity at the time the hash table is created. The &lt;i&gt;load factor&lt;i&gt; is a measure of how full the hash table is allowed to get before its capacity is automatically increased. When the number of entries in the hash table exceeds the product of the load factor and the current capacity, the hash table is &lt;i&gt;rehashed&lt;i&gt; (that is, internal data structures are rebuilt) so that the hash table has approximately twice the number of buckets. &lt;p&gt;As a general rule, the default load factor (.75) offers a good tradeoff between time and space costs. Higher values decrease the space overhead but increase the lookup cost (reflected in most of the operations of the &lt;tt&gt;HashMap&lt;tt&gt; class, including &lt;tt&gt;get&lt;tt&gt; and &lt;tt&gt;put&lt;tt&gt;). The expected number of entries in the map and its load factor should be taken into account when setting its initial capacity, so as to minimize the number of rehash operations. If the initial capacity is greater than the maximum number of entries divided by the load factor, no rehash operations will ever occur. &lt;p&gt;If many mappings are to be stored in a &lt;tt&gt;HashMap&lt;tt&gt; instance, creating it with a sufficiently large capacity will allow the mappings to be stored more efficiently than letting it perform automatic rehashing as needed to grow the table. Note that using many keys with the same {@code hashCode()} is a sure way to slow down performance of any hash table. To ameliorate impact, when keys are {@link Comparable}, this class may use comparison order among keys to help break ties. &lt;p&gt;&lt;strong&gt;Note that this implementation is not synchronized.&lt;strong&gt; If multiple threads access a hash map concurrently, and at least one of the threads modifies the map structurally, it &lt;i&gt;must&lt;i&gt; be synchronized externally. (A structural modification is any operation that adds or deletes one or more mappings; merely changing the value associated with a key that an instance already contains is not a structural modification.) This is typically accomplished by synchronizing on some object that naturally encapsulates the map. If no such object exists, the map should be &quot;wrapped&quot; using the {@link CollectionssynchronizedMap Collections.synchronizedMap} method. This is best done at creation time, to prevent accidental unsynchronized access to the map:&lt;pre&gt; Map m = Collections.synchronizedMap(new HashMap(...));&lt;pre&gt; &lt;p&gt;The iterators returned by all of this class's &quot;collection view methods&quot; are &lt;i&gt;fail-fast&lt;i&gt;: if the map is structurally modified at any time after the iterator is created, in any way except through the iterator's own &lt;tt&gt;remove&lt;tt&gt; method, the iterator will throw a {@link ConcurrentModificationException}. Thus, in the face of concurrent modification, the iterator fails quickly and cleanly, rather than risking arbitrary, non-deterministic behavior at an undetermined time in the future. &lt;p&gt;Note that the fail-fast behavior of an iterator cannot be guaranteed as it is, generally speaking, impossible to make any hard guarantees in the presence of unsynchronized concurrent modification. Fail-fast iterators throw &lt;tt&gt;ConcurrentModificationException&lt;tt&gt; on a best-effort basis. Therefore, it would be wrong to write a program that depended on this exception for its correctness: &lt;i&gt;the fail-fast behavior of iterators should be used only to detect bugs.&lt;i&gt; &lt;p&gt;This class is a member of the &lt;a href=&quot;{@docRoot}..technotesguidescollectionsindex.html&quot;&gt; Java Collections Framework&lt;a&gt;. @param &lt;K&gt; the type of keys maintained by this map @param &lt;V&gt; the type of mapped values @author Doug Lea @author Josh Bloch @author Arthur van Hoff @author Neal Gafter @see ObjecthashCode() @see Collection @see Map @see TreeMap @see Hashtable @since 1.2" />
      <item value="Implementation notes. This map usually acts as a binned (bucketed) hash table, but when bins get too large, they are transformed into bins of TreeNodes, each structured similarly to those in java.util.TreeMap. Most methods try to use normal bins, but relay to TreeNode methods when applicable (simply by checking instanceof a node). Bins of TreeNodes may be traversed and used like any others, but additionally support faster lookup when overpopulated. However, since the vast majority of bins in normal use are not overpopulated, checking for existence of tree bins may be delayed in the course of table methods. Tree bins (i.e., bins whose elements are all TreeNodes) are ordered primarily by hashCode, but in the case of ties, if two elements are of the same &quot;class C implements Comparable&lt;C&gt;&quot;, type then their compareTo method is used for ordering. (We conservatively check generic types via reflection to validate this -- see method comparableClassFor). The added complexity of tree bins is worthwhile in providing worst-case O(log n) operations when keys either have distinct hashes or are orderable, Thus, performance degrades gracefully under accidental or malicious usages in which hashCode() methods return values that are poorly distributed, as well as those in which many keys share a hashCode, so long as they are also Comparable. (If neither of these apply, we may waste about a factor of two in time and space compared to taking no precautions. But the only known cases stem from poor user programming practices that are already so slow that this makes little difference.) Because TreeNodes are about twice the size of regular nodes, we use them only when bins contain enough nodes to warrant use (see TREEIFY_THRESHOLD). And when they become too small (due to removal or resizing) they are converted back to plain bins. In usages with well-distributed user hashCodes, tree bins are rarely used. Ideally, under random hashCodes, the frequency of nodes in bins follows a Poisson distribution (http:en.wikipedia.orgwikiPoisson_distribution) with a parameter of about 0.5 on average for the default resizing threshold of 0.75, although with a large variance because of resizing granularity. Ignoring variance, the expected occurrences of list size k are (exp(-0.5) pow(0.5, k) factorial(k)). The first values are: 0: 0.60653066 1: 0.30326533 2: 0.07581633 3: 0.01263606 4: 0.00157952 5: 0.00015795 6: 0.00001316 7: 0.00000094 8: 0.00000006 more: less than 1 in ten million The root of a tree bin is normally its first node. However, sometimes (currently only upon Iterator.remove), the root might be elsewhere, but can be recovered following parent links (method TreeNode.root()). All applicable internal methods accept a hash code as an argument (as normally supplied from a public method), allowing them to call each other without recomputing user hashCodes. Most internal methods also accept a &quot;tab&quot; argument, that is normally the current table, but may be a new or old one when resizing or converting. When bin lists are treeified, split, or untreeified, we keep them in the same relative accesstraversal order (i.e., field Node.next) to better preserve locality, and to slightly simplify handling of splits and traversals that invoke iterator.remove. When using comparators on insertion, to keep a total ordering (or as close as is required here) across rebalancings, we compare classes and identityHashCodes as tie-breakers. The use and transitions among plain vs tree modes is complicated by the existence of subclass LinkedHashMap. See below for hook methods defined to be invoked upon insertion, removal and access that allow LinkedHashMap internals to otherwise remain independent of these mechanics. (This also requires that a map instance be passed to some utility methods that may create new nodes.) The concurrent-programming-like SSA-based coding style helps avoid aliasing errors amid all of the twisty pointer operations." />
      <item value="Tie-breaking utility for ordering insertions when equal hashCodes and non-comparable. We don't require a total order, just a consistent insertion rule to maintain equivalence across rebalancings. Tie-breaking further than necessary simplifies testing a bit." />
      <item value="tie Break Order" />
      <item value="Returns a list of non-TreeNodes replacing those linked from this node." />
      <item value="Removes the given node, that must be present before this call. This is messier than typical red-black deletion code because we cannot swap the contents of an interior node with a leaf successor that is pinned by &quot;next&quot; pointers that are accessible independently during traversal. So instead we swap the tree linkages. If the current tree appears to have too few nodes, the bin is converted back to a plain bin. (The test triggers somewhere between 2 and 6 nodes, depending on tree structure)." />
      <item value="balance Insertion" />
      <item value="balance Deletion" />
      <item value="Recursive invariant check" />
      <item value="bins" />
      <item value="Forms tree of the nodes linked from this node." />
      <item value="treeify" />
      <item value="Replaces all linked nodes in bin at index for given hash unless table is too small, in which case resizes instead." />
      <item value="Splits nodes in a tree bin into lower and upper tree bins, or untreeifies if now too small. Called only from resize; see above discussion about split bits and indices. @param map the map @param tab the table for recording bin heads @param index the index of the table being split @param bit the bit of hash to split on" />
      <item value="Initializes or doubles table size. If null, allocates in accord with initial capacity target held in field threshold. Otherwise, because we are using power-of-two expansion, the elements from each bin must either stay at same index, or move with a power of two offset in the new table." />
      <item value="lo Tail" />
      <item value="lo Head" />
      <item value="preserve order" />
      <item value="MAXIMUM CAPACITY" />
      <item value="initial capacity was placed in threshold" />
      <item value="The maximum capacity, used if a higher value is implicitly specified by either of the constructors with arguments. MUST be a power of two &lt;= 1&lt;&lt;30." />
      <item value="previous" />
      <item value="@param evict if false, the table is in creation mode." />
      <item value="evict" />
      <item value="capacity" />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="209" />
        <entry key="ENGLISH" value="210" />
        <entry key="IRISH" value="1" />
        <entry key="LATIN" value="2" />
        <entry key="SLOVENIAN" value="1" />
        <entry key="SPANISH" value="3" />
      </map>
    </option>
  </component>
  <component name="Cache">
    <option name="lastTrimTime" value="1657526679706" />
  </component>
</application>